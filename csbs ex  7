import numpy as np
import pandas as pd
from sklearn.datasets import load_iris

# Load the Iris dataset
iris = load_iris()
X = iris.data  # Feature matrix
y = iris.target  # Labels

# Compute the mean vectors for each class
mean_vectors = []
for cl in np.unique(y):
    mean_vectors.append(np.mean(X[y==cl], axis=0))
mean_vectors = np.array(mean_vectors)

# Compute the within-class scatter matrix (Sw)
Sw = np.zeros((X.shape[1], X.shape[1]))
for cl, mv in zip(np.unique(y), mean_vectors):
    class_scatter = np.cov(X[y==cl].T)  # Covariance matrix for each class
    Sw += class_scatter

# Compute the between-class scatter matrix (Sb)
overall_mean = np.mean(X, axis=0)
Sb = np.zeros((X.shape[1], X.shape[1]))
for i, mean_vec in enumerate(mean_vectors):
    n = X[y==i].shape[0]
    mean_vec = mean_vec.reshape(X.shape[1], 1)  # Make column vector
    overall_mean = overall_mean.reshape(X.shape[1], 1)  # Make column vector
    Sb += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)

# Compute the eigenvalues and eigenvectors of the matrix Sw^-1 * Sb
eigen_values, eigen_vectors = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))

# Sort eigenvalues and their corresponding eigenvectors
eigen_pairs = [(np.abs(eigen_values[i]), eigen_vectors[:, i]) for i in range(len(eigen_values))]
eigen_pairs = sorted(eigen_pairs, key=lambda k: k[0], reverse=True)

# Print the eigenvalues
print("Eigenvalues in decreasing order:\n")
for eigen_value in eigen_pairs:
    print(eigen_value[0])

# Choose the top k eigenvectors based on the largest eigenvalues
# (for this example, we choose the top 2 eigenvectors)
W = np.hstack((eigen_pairs[0][1].reshape(X.shape[1], 1), eigen_pairs[1][1].reshape(X.shape[1], 1)))

# Project the data onto the new feature space
X_lda = X.dot(W)

print("\nProjected Data (first 5 samples):\n",Â X_lda[:5])
